{"cells": [{"cell_type": "code", "source": ["# Mount Google Drive\n", "from google.colab import drive\n", "import zipfile\n", "import os\n", "drive.mount('/content/drive')"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Unzip dataset\n", "!unzip -q /content/drive/MyDrive/HAM10000.zip -d /content/drive/MyDrive/"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Dataset paths\n", "base_path = \"/content/drive/MyDrive/HAM10000\"\n", "csv_path = f\"{base_path}/HAM10000_metadata.csv\"\n", "img_folder1 = f\"{base_path}/HAM10000_images_part_1\"\n", "img_folder2 = f\"{base_path}/HAM10000_images_part_2\""], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Import libraries\n", "import pandas as pd\n", "import numpy as np\n", "from PIL import Image\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.metrics import classification_report, confusion_matrix\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n", "from torchvision import transforms, models\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Load and preprocess metadata\n", "df = pd.read_csv(csv_path)\n", "\n", "def get_image_path(img_id):\n", "    p1 = os.path.join(img_folder1, f\"{img_id}.jpg\")\n", "    p2 = os.path.join(img_folder2, f\"{img_id}.jpg\")\n", "    return p1 if os.path.exists(p1) else p2\n", "\n", "df['path'] = df['image_id'].apply(get_image_path)"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Label encoding\n", "le = LabelEncoder()\n", "df['label'] = le.fit_transform(df['dx'])\n", "class_names = le.classes_\n", "print(\"Classes:\", class_names)"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Train-test split\n", "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Transforms\n", "transform = transforms.Compose([\n", "    transforms.RandomHorizontalFlip(),\n", "    transforms.RandomRotation(15),\n", "    transforms.Resize((224, 224)),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n", "])"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Dataset class\n", "class SkinDataset(Dataset):\n", "    def __init__(self, df, transform=None):\n", "        self.df = df.reset_index(drop=True)\n", "        self.transform = transform\n", "\n", "    def __len__(self):\n", "        return len(self.df)\n", "\n", "    def __getitem__(self, idx):\n", "        image = Image.open(self.df.loc[idx, 'path']).convert(\"RGB\")\n", "        label = self.df.loc[idx, 'label']\n", "        if self.transform:\n", "            image = self.transform(image)\n", "        return image, label\n", "\n", "train_ds = SkinDataset(train_df, transform=transform)\n", "val_ds = SkinDataset(val_df, transform=transform)"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Sampler and dataloaders\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "class_counts = train_df['label'].value_counts().sort_index()\n", "weights = 1. / class_counts\n", "class_weights = torch.FloatTensor(weights.values).to(device)\n", "\n", "sample_weights = train_df['label'].map(weights).values\n", "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n", "\n", "train_loader = DataLoader(train_ds, batch_size=32, sampler=sampler, num_workers=2)\n", "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Model setup\n", "model = models.resnet50(pretrained=True)\n", "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n", "model = model.to(device)\n", "criterion = nn.CrossEntropyLoss(weight=class_weights)\n", "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Training loop\n", "num_epochs = 10\n", "for epoch in range(num_epochs):\n", "    model.train()\n", "    total_loss = 0\n", "    for images, labels in train_loader:\n", "        images, labels = images.to(device), labels.to(device)\n", "        optimizer.zero_grad()\n", "        outputs = model(images)\n", "        loss = criterion(outputs, labels)\n", "        loss.backward()\n", "        optimizer.step()\n", "        total_loss += loss.item()\n", "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Evaluation\n", "model.eval()\n", "correct = 0\n", "total = 0\n", "all_labels = []\n", "all_preds = []\n", "with torch.no_grad():\n", "    for images, labels in val_loader:\n", "        images, labels = images.to(device), labels.to(device)\n", "        outputs = model(images)\n", "        _, preds = torch.max(outputs, 1)\n", "        correct += (preds == labels).sum().item()\n", "        total += labels.size(0)\n", "        all_labels.extend(labels.cpu().numpy())\n", "        all_preds.extend(preds.cpu().numpy())\n", "print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"], "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Confusion matrix\n", "print(\"\\nClassification Report:\")\n", "print(classification_report(all_labels, all_preds, target_names=class_names))\n", "cm = confusion_matrix(all_labels, all_preds)\n", "plt.figure(figsize=(10, 8))\n", "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n", "plt.xlabel('Predicted')\n", "plt.ylabel('True')\n", "plt.title('Confusion Matrix')\n", "plt.show()"], "metadata": {}, "execution_count": null, "outputs": []}], "metadata": {"colab": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 0}